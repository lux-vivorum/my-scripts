# --- –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å —É–º–Ω—ã–º throttling ---
from __future__ import print_function
import os, pickle, time, csv, re, json, argparse, logging
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from typing import Dict, Optional, Any, List
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ tqdm: pip install tqdm")

CONFIG: Dict[str, Any] = {
    'scopes': ['https://www.googleapis.com/auth/gmail.readonly'],
    'token_file': 'token.pickle',
    'credentials_file': 'credentials.json',
    'result_file': 'sender_counts.csv',
    'initial_delay': 0.05,  # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –Ω–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
    'max_delay': 8.0,       # –£–º–µ–Ω—å—à–∏–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É
    'backoff_factor': 2.0,  # –ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    'success_reduction': 0.85, # –ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ø—Ä–∏ —É—Å–ø–µ—Ö–∞—Ö
    'max_retries': 3,
    'chunk_size': 15,       # –£–≤–µ–ª–∏—á–∏–ª–∏ —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
    'adaptive_throttling': True,
    'turbo_mode': False,    # –†–µ–∂–∏–º –¥–ª—è –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    'success_threshold': 5  # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –∫–∞–∂–¥—ã–µ 5 —É—Å–ø–µ—Ö–æ–≤
}

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class AdaptiveThrottler:
    """–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–µ–≥—É–ª—è—Ç–æ—Ä —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    def __init__(self):
        self.current_delay = CONFIG['initial_delay']
        self.consecutive_successes = 0
        self.consecutive_failures = 0
        
    def on_success(self):
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ"""
        self.consecutive_successes += 1
        self.consecutive_failures = 0
        
        # –ö–∞–∂–¥—ã–µ N —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —É–º–µ–Ω—å—à–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
        threshold = CONFIG.get('success_threshold', 5)
        if self.consecutive_successes >= threshold:
            old_delay = self.current_delay
            self.current_delay = max(
                CONFIG['initial_delay'],
                self.current_delay * CONFIG['success_reduction']
            )
            self.consecutive_successes = 0
            if abs(old_delay - self.current_delay) > 0.01:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
                logging.info(f"üöÄ –£—Å–∫–æ—Ä–∏–ª–∏: {old_delay:.3f}s ‚Üí {self.current_delay:.3f}s")
    
    def on_rate_limit(self):
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ 429 –æ—à–∏–±–∫–µ"""
        self.consecutive_failures += 1
        self.consecutive_successes = 0
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
        old_delay = self.current_delay
        self.current_delay = min(
            CONFIG['max_delay'],
            self.current_delay * CONFIG['backoff_factor']
        )
        logging.warning(f"‚ö†Ô∏è  429! –ó–∞–º–µ–¥–ª–∏–ª–∏: {old_delay:.3f}s ‚Üí {self.current_delay:.3f}s")
    
    def wait(self):
        """–û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        # –í —Ç—É—Ä–±–æ-—Ä–µ–∂–∏–º–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏
        if CONFIG.get('turbo_mode', False):
            time.sleep(max(0.01, self.current_delay * 0.5))
        else:
            time.sleep(self.current_delay)
    
    def get_current_delay(self) -> float:
        return self.current_delay

class GmailAnalyzer:
    def __init__(self):
        self.service: Optional[Any] = None
        self.sender_counts: Dict[str,int] = defaultdict(int)
        self.domain_counts: Dict[str,int] = defaultdict(int)
        self.total_processed = 0
        self.total_errors = 0
        self.throttler = AdaptiveThrottler()

    def get_service(self):
        creds = None
        if os.path.exists(CONFIG['token_file']):
            with open(CONFIG['token_file'],'rb') as f:
                creds = pickle.load(f)
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(CONFIG['credentials_file'], CONFIG['scopes'])
                creds = flow.run_local_server(port=0)
            with open(CONFIG['token_file'],'wb') as f:
                pickle.dump(creds, f)
        self.service = build('gmail','v1',credentials=creds)

    @staticmethod
    def extract_email(sender: str) -> str:
        if not sender:
            return "unknown"
        # –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è email
        pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        m = re.search(pattern, sender, re.IGNORECASE)
        return m.group(0).lower() if m else sender.lower()

    @staticmethod
    def extract_domain(email: str) -> str:
        return email.split('@')[-1].lower() if '@' in email else 'unknown'

    def _process_single_message(self, message_id: str) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        retry_count = 0
        
        while retry_count <= CONFIG['max_retries']:
            try:
                # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
                if CONFIG['adaptive_throttling']:
                    self.throttler.wait()
                
                response = self.service.users().messages().get(
                    userId='me', 
                    id=message_id, 
                    format='metadata'
                ).execute()
                
                # –£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                self.throttler.on_success()
                self._extract_sender_info(response)
                return True
                
            except HttpError as e:
                if e.resp.status == 429:
                    self.throttler.on_rate_limit()
                    retry_count += 1
                    
                    if retry_count <= CONFIG['max_retries']:
                        # –ë–æ–ª–µ–µ —É–º–Ω–∞—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ 429
                        extra_wait = min(20, 2 * retry_count)  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø–∞—É–∑—É
                        logging.warning(f"429 –¥–ª—è {message_id}, –ø–æ–ø—ã—Ç–∫–∞ {retry_count}/{CONFIG['max_retries']}, –∂–¥–µ–º {extra_wait}s")
                        time.sleep(extra_wait)
                    else:
                        logging.error(f"–ò—Å—á–µ—Ä–ø–∞–Ω—ã –ø–æ–ø—ã—Ç–∫–∏ –¥–ª—è {message_id}")
                        self.total_errors += 1
                        return False
                else:
                    logging.error(f"HTTP –æ—à–∏–±–∫–∞ {e.resp.status} –¥–ª—è {message_id}: {e}")
                    self.total_errors += 1
                    return False
                    
            except Exception as e:
                logging.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è {message_id}: {e}")
                self.total_errors += 1
                return False
        
        return False

    def _extract_sender_info(self, response: Dict[str, Any]):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ"""
        try:
            payload = response.get('payload', {})
            headers = payload.get('headers', [])
            
            sender = None
            for header in headers:
                if header.get('name', '').lower() == 'from':
                    sender = self.extract_email(header.get('value', ''))
                    break
            
            if sender and sender != "unknown":
                self.sender_counts[sender] += 1
                self.domain_counts[self.extract_domain(sender)] += 1
            else:
                self.sender_counts["unknown"] += 1
                self.domain_counts["unknown"] += 1
            
            self.total_processed += 1
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è: {e}")
            self.sender_counts["unknown"] += 1
            self.domain_counts["unknown"] += 1
            self.total_processed += 1

    def _process_chunk(self, messages: List[Dict[str, str]], progress_bar=None) -> int:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        processed = 0
        
        for msg in messages:
            success = self._process_single_message(msg['id'])
            if success:
                processed += 1
            
            if progress_bar:
                progress_bar.update(1)
                # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Å —Ç–µ–∫—É—â–µ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
                current_delay = self.throttler.get_current_delay()
                progress_bar.set_description(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ (–∑–∞–¥–µ—Ä–∂–∫–∞: {current_delay:.2f}s)")
        
        return processed

    def count_emails(self, days_back: Optional[int]=None, query: Optional[str]=None, max_emails: Optional[int]=None):
        if not self.service: 
            self.get_service()
            
        q = ''
        if days_back:
            date_filter = (datetime.now(timezone.utc)-timedelta(days=days_back)).strftime('%Y/%m/%d')
            q += f"after:{date_filter} "
        if query: 
            q += query
        q = q.strip()
        
        logging.info(f"–ü–æ–∏—Å–∫: {q if q else '–í—Å–µ –ø–∏—Å—å–º–∞'}")

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        all_messages = []
        page_token = None
        
        while True:
            try:
                resp = self.service.users().messages().list(
                    userId='me', q=q,
                    maxResults=1000, pageToken=page_token
                ).execute()
                msgs = resp.get('messages',[])
                if not msgs: 
                    break
                    
                all_messages.extend(msgs)
                
                if max_emails and len(all_messages) >= max_emails:
                    all_messages = all_messages[:max_emails]
                    break
                    
                page_token = resp.get('nextPageToken')
                if not page_token: 
                    break
                    
            except HttpError as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")
                break

        if not all_messages:
            logging.info("–°–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return

        total_messages = len(all_messages)
        logging.info(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {total_messages}")
        logging.info(f"–ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: {CONFIG['initial_delay']}s")
        
        # Progress bar
        progress_bar = None
        if TQDM_AVAILABLE:
            progress_bar = tqdm(
                total=total_messages, 
                desc=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ (–∑–∞–¥–µ—Ä–∂–∫–∞: {CONFIG['initial_delay']}s)",
                unit="msg"
            )

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —á–∞–Ω–∫–∞–º–∏
        start_time = time.time()
        processed_chunks = 0
        
        for i in range(0, total_messages, CONFIG['chunk_size']):
            chunk = all_messages[i:i+CONFIG['chunk_size']]
            processed_in_chunk = self._process_chunk(chunk, progress_bar)
            processed_chunks += 1
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5 —á–∞–Ω–∫–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            if processed_chunks % 5 == 0:
                elapsed = time.time() - start_time
                rate = self.total_processed / elapsed if elapsed > 0 else 0
                current_delay = self.throttler.get_current_delay()
                logging.info(f"üìä –ß–∞–Ω–∫ {processed_chunks}: {self.total_processed}/{total_messages} —Å–æ–æ–±—â–µ–Ω–∏–π, {rate:.1f} msg/s, –∑–∞–¥–µ—Ä–∂–∫–∞: {current_delay:.3f}s")

        if progress_bar: 
            progress_bar.close()

        elapsed_time = time.time() - start_time
        rate = self.total_processed / elapsed_time if elapsed_time > 0 else 0
        
        logging.info(f"=== –ó–ê–í–ï–†–®–ï–ù–û ===")
        logging.info(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.total_processed}")
        logging.info(f"–û—à–∏–±–æ–∫: {self.total_errors}")
        logging.info(f"–í—Ä–µ–º—è: {elapsed_time:.1f}s")
        logging.info(f"–°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {rate:.1f} —Å–æ–æ–±—â–µ–Ω–∏–π/—Å–µ–∫")
        logging.info(f"–§–∏–Ω–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: {self.throttler.get_current_delay():.2f}s")

    def save_csv(self, filename: str = 'sender_counts.csv'):
        with open(filename,'w', newline='', encoding='utf-8') as f:
            w = csv.writer(f)
            w.writerow(['Sender','Count','Domain'])
            for s, c in sorted(self.sender_counts.items(), key=lambda x: x[1], reverse=True):
                w.writerow([s, c, self.extract_domain(s)])
        logging.info(f"CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

    def save_json(self, filename: str = 'report.json'):
        report = {
            'total_processed': self.total_processed,
            'total_errors': self.total_errors,
            'unique_senders': len(self.sender_counts),
            'unique_domains': len(self.domain_counts),
            'final_delay': self.throttler.get_current_delay(),
            'top_senders': dict(list(sorted(self.sender_counts.items(), key=lambda x: x[1], reverse=True))[:50]),
            'top_domains': dict(list(sorted(self.domain_counts.items(), key=lambda x: x[1], reverse=True))[:20])
        }
        with open(filename,'w', encoding='utf-8') as f: 
            json.dump(report, f, ensure_ascii=False, indent=2)
        logging.info(f"JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        return {
            'total_emails': self.total_processed,
            'total_errors': self.total_errors,
            'unique_senders': len(self.sender_counts),
            'unique_domains': len(self.domain_counts),
            'final_delay': self.throttler.get_current_delay(),
            'success_rate': (self.total_processed / (self.total_processed + self.total_errors)) * 100 if (self.total_processed + self.total_errors) > 0 else 0,
            'top_domain': max(self.domain_counts.items(), key=lambda x: x[1]) if self.domain_counts else None,
            'top_sender': max(self.sender_counts.items(), key=lambda x: x[1]) if self.sender_counts else None
        }


def main():
    parser = argparse.ArgumentParser(description='Gmail Analyzer - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π')
    parser.add_argument('--days', type=int, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞')
    parser.add_argument('--query', type=str, help='–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å')
    parser.add_argument('--output', type=str, help='–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞')
    parser.add_argument('--json', action='store_true', help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–∞–∫–∂–µ JSON –æ—Ç—á–µ—Ç')
    parser.add_argument('--max-emails', type=int, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--chunk-size', type=int, default=15, help='–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 15)')
    parser.add_argument('--initial-delay', type=float, help='–ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö')
    parser.add_argument('--max-delay', type=float, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö')
    parser.add_argument('--turbo', action='store_true', help='–¢—É—Ä–±–æ —Ä–µ–∂–∏–º (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω–µ–µ)')
    parser.add_argument('--conservative', action='store_true', help='–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –Ω–∞–¥–µ–∂–Ω–µ–µ)')
    
    args = parser.parse_args()

    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    if args.chunk_size:
        CONFIG['chunk_size'] = args.chunk_size
    if args.initial_delay:
        CONFIG['initial_delay'] = args.initial_delay
    if args.max_delay:
        CONFIG['max_delay'] = args.max_delay
    
    # –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã
    if args.turbo:
        CONFIG['turbo_mode'] = True
        CONFIG['initial_delay'] = 0.02
        CONFIG['success_threshold'] = 3
        CONFIG['chunk_size'] = 20
        logging.info("üöÄ –¢–£–†–ë–û –†–ï–ñ–ò–ú –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!")
    elif args.conservative:
        CONFIG['initial_delay'] = 0.2
        CONFIG['success_threshold'] = 10
        CONFIG['chunk_size'] = 8
        CONFIG['max_delay'] = 15.0
        logging.info("üêå –ö–û–ù–°–ï–†–í–ê–¢–ò–í–ù–´–ô –†–ï–ñ–ò–ú –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!")

    analyzer = GmailAnalyzer()
    
    try:
        analyzer.count_emails(
            days_back=args.days, 
            query=args.query, 
            max_emails=args.max_emails
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output_file = args.output or CONFIG['result_file']
        analyzer.save_csv(output_file)
        
        if args.json:
            json_file = output_file.replace('.csv', '_report.json') if args.output else 'report.json'
            analyzer.save_json(json_file)
        
        # –í—ã–≤–æ–¥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats = analyzer.get_statistics()
        print(f"\n=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===")
        print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total_emails']}")
        print(f"–û—à–∏–±–æ–∫: {stats['total_errors']}")
        print(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {stats['success_rate']:.1f}%")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π: {stats['unique_senders']}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤: {stats['unique_domains']}")
        print(f"–§–∏–Ω–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: {stats['final_delay']:.2f}s")
        
        if stats['top_sender']:
            print(f"–¢–æ–ø –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å: {stats['top_sender'][0]} ({stats['top_sender'][1]} –ø–∏—Å–µ–º)")
        if stats['top_domain']:
            print(f"–¢–æ–ø –¥–æ–º–µ–Ω: {stats['top_domain'][0]} ({stats['top_domain'][1]} –ø–∏—Å–µ–º)")
            
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())