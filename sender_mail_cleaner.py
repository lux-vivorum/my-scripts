#!/usr/bin/env python3
"""
Gmail Cleaner Pro - –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ—á—Ç–æ–π
–í–µ—Ä—Å–∏—è: 2.1
–ê–≤—Ç–æ—Ä: –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è (–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –°–∏–Ω—Ç–∞–∫—Å–∏—Å –∏ –û—Ç—Å—Ç—É–ø—ã)
"""

import os
import time
import json
import logging
import re
import argparse
import webbrowser
import math
import random
import base64
from datetime import datetime, timezone, timedelta
from typing import List, Tuple, Optional, Generator
from email.utils import parsedate_to_datetime
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import BatchHttpRequest
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

# === –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ ===
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False

try:
    from dateutil import parser as dateutil_parser
    DATEUTIL_AVAILABLE = True
except ImportError:
    DATEUTIL_AVAILABLE = False

try:
    from fuzzywuzzy import fuzz
    FUZZYWUZZY_AVAILABLE = True
except ImportError:
    FUZZYWUZZY_AVAILABLE = False

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

try:
    import pyperclip
    PYPERCLIP_AVAILABLE = True
except ImportError:
    PYPERCLIP_AVAILABLE = False

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ===
DEFAULT_CONFIG = {
    'scopes': ['https://www.googleapis.com/auth/gmail.modify'],
    'batch_size': 100,
    'batch_delete_size': 1000,
    'delay_between_requests': 0.1,
    'sleep_after_list': 0.2,
    'credentials_file': 'credentials.json',
    'token_file': 'token.json',
    'log_file': 'gmail_cleaner_pro.log',
    'backup_dir': 'email_backups',
    'stats_dir': 'stats',
    'subject_similarity_threshold': 85,
    'max_retries': 5,
    'initial_backoff': 1.0,
    'max_backoff': 60.0,
    'dry_run': False,
    'auto_backup': True,
    'use_batch_delete': True,
}


def load_config(config_file: str = 'gmail_cleaner_config.json') -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—É—é."""
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                custom_config = json.load(f)
                config = DEFAULT_CONFIG.copy()
                config.update(custom_config)
                return config
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
    return DEFAULT_CONFIG.copy()


def setup_logging(log_file: str):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è."""
    os.makedirs(os.path.dirname(log_file) if os.path.dirname(log_file) else '.', exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
def display_top_senders(df: 'pd.DataFrame'):
    """–í—ã–≤–æ–¥–∏—Ç —Ç–æ–ø-10 —Å–∞–º—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π."""
    if df is None or df.empty:
        return
        
    print("\n--- –¢–û–ü-10 –°–ê–ú–´–• –ê–ö–¢–ò–í–ù–´–• –û–¢–ü–†–ê–í–ò–¢–ï–õ–ï–ô (–∏–∑ sender_counts.csv) ---")
    top_senders = df.head(10)
    
    # –†–∞—Å—á–µ—Ç —à–∏—Ä–∏–Ω—ã –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
    max_len = top_senders['sender_email'].str.len().max() if not top_senders.empty else 40
    
    for index, row in top_senders.iterrows():
        # –í—ã–≤–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å + 1 –¥–ª—è –Ω—É–º–µ—Ä–∞—Ü–∏–∏
        print(f"{index+1:2}. {row['sender_email']:<{max_len}} | –ü–∏—Å–µ–º: {row['message_count']}")
    print("-----------------------------------------------------------------")


class GmailCleanerPro:
    """–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —á–∏—Å—Ç–∫–∏ Gmail."""
    
    def __init__(self, config: dict = None):
        self.config = load_config()
        if config:
            self.config.update(config)
            
        setup_logging(self.config['log_file'])
        self.logger = logging.getLogger(__name__)
        self.service = None
        self.stats = {
            'found': 0,
            'trashed': 0,
            'errors': 0,
            'skipped': 0,
            'backed_up': 0
        }
        self.messages_cache: List[Tuple[datetime, str, str]] = []

    # ==================== –ê–£–¢–ï–ù–¢–ò–§–ò–ö–ê–¶–ò–Ø ====================
    
    def authenticate_gmail_api(self):
        """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ Gmail API."""
        creds = None
        
        if os.path.exists(self.config['token_file']):
            try:
                creds = Credentials.from_authorized_user_file(
                    self.config['token_file'], 
                    self.config['scopes']
                )
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–∫–µ–Ω–∞: {e}")
                os.remove(self.config['token_file'])
                creds = None

        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                try:
                    creds.refresh(Request())
                except Exception:
                    creds = None
            
            if not creds:
                if not os.path.exists(self.config['credentials_file']):
                    raise FileNotFoundError(
                        f"‚ùå –§–∞–π–ª {self.config['credentials_file']} –Ω–µ –Ω–∞–π–¥–µ–Ω!\n"
                        "    –°–∫–∞—á–∞–π—Ç–µ credentials.json –∏–∑ Google Cloud Console."
                    )
                
                flow = InstalledAppFlow.from_client_secrets_file(
                    self.config['credentials_file'], 
                    self.config['scopes']
                )
                creds = flow.run_local_server(port=0)
            
            with open(self.config['token_file'], 'w', encoding='utf-8') as token:
                token.write(creds.to_json())

        self.service = build('gmail', 'v1', credentials=creds)
        self.logger.info("‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ Gmail API")

    # ==================== –£–¢–ò–õ–ò–¢–´ ====================
    
    @staticmethod
    def validate_email(email: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è email –∞–¥—Ä–µ—Å–∞."""
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∑–∞–∫—Ä—ã–≤–∞—é—â–∞—è –∫–∞–≤—ã—á–∫–∞ –∏ —Å–∫–æ–±–∫–∞
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$' 
        return re.match(pattern, email) is not None

    @staticmethod
    def validate_domain(domain: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–º–µ–Ω–∞."""
        # –î–æ–±–∞–≤–ª–µ–Ω –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–º–µ–Ω–∞
        pattern = r'^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$' 
        return re.match(pattern, domain) is not None

    def exponential_backoff(self, attempt: int) -> float:
        """–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å jitter."""
        base_delay = self.config['initial_backoff'] * (2 ** attempt)
        delay = min(base_delay, self.config['max_backoff'])
        jitter = delay * 0.2 * (random.random() - 0.5)
        return delay + jitter

    def parse_email_date(self, date_str: str) -> datetime:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –ø–∏—Å—å–º–∞."""
        if not date_str:
            return datetime.min.replace(tzinfo=timezone.utc)
        
        try:
            dt = parsedate_to_datetime(date_str)
            if dt and dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt
        except Exception:
            pass
        
        if DATEUTIL_AVAILABLE:
            try:
                dt = dateutil_parser.parse(date_str, fuzzy=True)
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=timezone.utc)
                return dt
            except Exception:
                pass
        
        return datetime.min.replace(tzinfo=timezone.utc)

    def clean_subject(self, subject: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–º—ã –ø–∏—Å—å–º–∞ –æ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤."""
        cleaned = re.sub(r'^(re|fwd|fw|aw):\s*', '', subject, flags=re.IGNORECASE)
        cleaned = re.sub(r'\s*[\(\[]\d+[\)\]]\s*$', '', cleaned)
        return cleaned.strip().lower()

    # ==================== –ü–û–ò–°–ö –ü–ò–°–ï–ú ====================
    
    def build_search_query(self, sender_email=None, days_ago=None, 
                           additional_query=None, min_size_mb=None) -> Optional[str]:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
        parts = []
        
        if sender_email:
            sender_email = sender_email.strip()
            
            if self.validate_email(sender_email):
                parts.append(f"from:{sender_email}")
                self.logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–∏—Å–µ–º –æ—Ç: {sender_email}")
                
            elif sender_email.startswith('@'):
                domain = sender_email[1:]
                if self.validate_domain(domain):
                    parts.append(f"from:{sender_email}")
                    self.logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–∏—Å–µ–º –æ—Ç –¥–æ–º–µ–Ω–∞: {sender_email}")
                    print(f"\n‚úÖ –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –ø–∏—Å–µ–º –æ—Ç –¥–æ–º–µ–Ω–∞ {sender_email}")
                else:
                    self.logger.error(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π –¥–æ–º–µ–Ω: {domain}")
                    print(f"\n‚ùå –û–®–ò–ë–ö–ê: '{domain}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º –¥–æ–º–µ–Ω–æ–º!")
                    return None
                
            elif self.validate_domain(sender_email):
                parts.append(f"from:@{sender_email}")
                self.logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–∏—Å–µ–º –æ—Ç –¥–æ–º–µ–Ω–∞: @{sender_email}")
                print(f"\n‚úÖ –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: –∏—â—É –≤—Å–µ –ø–∏—Å—å–º–∞ –æ—Ç –¥–æ–º–µ–Ω–∞ @{sender_email}")
                
            else:
                self.logger.error(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π email/–¥–æ–º–µ–Ω: {sender_email}")
                print(f"\n‚ùå –û–®–ò–ë–ö–ê: '{sender_email}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º email –∏–ª–∏ –¥–æ–º–µ–Ω–æ–º!")
                print("\n    –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:")
                print("    ‚úÖ noreply@fuib.com    (–ø–æ–ª–Ω—ã–π email)")
                print("    ‚úÖ fuib.com            (–¥–æ–º–µ–Ω - –Ω–∞–π–¥–µ—Ç –í–°–ï –ø–∏—Å—å–º–∞ –æ—Ç @fuib.com)")
                print("    ‚úÖ @fuib.com           (–¥–æ–º–µ–Ω —Å @)\n")
                return None
        
        if days_ago:
            date_str = (datetime.now() - timedelta(days=days_ago)).strftime('%Y/%m/%d')
            parts.append(f"before:{date_str}")
        
        if min_size_mb:
            size_bytes = int(min_size_mb * 1024 * 1024)
            parts.append(f"larger:{size_bytes}")
        
        if additional_query:
            parts.append(additional_query)
        
        query = " ".join(parts)
        
        if not query.strip():
            self.logger.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
            print("\n‚ö†Ô∏è –ù–µ —É–∫–∞–∑–∞–Ω—ã –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞. –£–∫–∞–∂–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä.")
            return None
            
        return query

    def get_message_metadata_with_retry(self, msg_id: str) -> Optional[Tuple[datetime, str, str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–∏—Å—å–º–∞ —Å retry."""
        retry_count = 0
        
        while retry_count < self.config['max_retries']:
            try:
                response = self.service.users().messages().get(
                    userId='me', 
                    id=msg_id, 
                    format='metadata', 
                    metadataHeaders=['Subject', 'Date', 'From']
                ).execute()
                
                headers = response.get('payload', {}).get('headers', [])
                subject = next((h['value'] for h in headers if h['name'].lower() == 'subject'), "–ë–µ–∑ —Ç–µ–º—ã")
                date_str = next((h['value'] for h in headers if h['name'].lower() == 'date'), None)
                date_obj = self.parse_email_date(date_str)
                
                return (date_obj, response['id'], subject)
                
            except HttpError as e:
                retry_count += 1
                if e.resp.status in [429, 403, 500, 503]:
                    backoff_time = self.exponential_backoff(retry_count)
                    self.logger.warning(f"‚è≥ Rate limit. –û–∂–∏–¥–∞–Ω–∏–µ {backoff_time:.1f}s...")
                    time.sleep(backoff_time)
                else:
                    self.stats['errors'] += 1
                    self.logger.error(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {e}")
                    return None
            except Exception as e:
                self.stats['errors'] += 1
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
                return None
            
        return None

    def find_emails_by_criteria(self, query: str) -> List[Tuple[datetime, str, str]]:
        """–ü–æ–∏—Å–∫ –ø–∏—Å–µ–º –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º."""
        self.logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–∏—Å–µ–º: {query}")
        self.messages_cache.clear()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ ID
        all_message_ids = self._fetch_all_message_ids(query)
        
        if not all_message_ids:
            self.logger.info("üì≠ –ü–∏—Å—å–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return []
        
        self.logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(all_message_ids)} –ø–∏—Å–µ–º. –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        progress_bar = tqdm(
            total=len(all_message_ids), 
            desc="–ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö", 
            unit="–ø–∏—Å–µ–º"
        ) if TQDM_AVAILABLE else None
        
        for msg_id in all_message_ids:
            result = self.get_message_metadata_with_retry(msg_id)
            if result:
                self.messages_cache.append(result)
            
            if progress_bar:
                progress_bar.update(1)
            
            time.sleep(self.config['delay_between_requests'])
        
        if progress_bar:
            progress_bar.close()
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
        valid_messages = [
            (dt, mid, subj) 
            for dt, mid, subj in self.messages_cache 
            if dt != datetime.min.replace(tzinfo=timezone.utc)
        ]
        valid_messages.sort(key=lambda x: x[0])
        
        self.messages_cache = valid_messages
        self.stats['found'] = len(self.messages_cache)
        
        return self.messages_cache

    def _fetch_all_message_ids(self, query: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö ID –ø–∏—Å–µ–º –ø–æ –∑–∞–ø—Ä–æ—Å—É."""
        all_ids = []
        page_token = None
        
        while True:
            try:
                response = self.service.users().messages().list(
                    userId='me',
                    q=f"{query} in:anywhere -in:trash",
                    maxResults=self.config['batch_size'],
                    pageToken=page_token
                ).execute()
                
                messages = response.get('messages', [])
                if not messages:
                    break
                
                all_ids.extend([msg['id'] for msg in messages])
                page_token = response.get('nextPageToken')
                
                if not page_token:
                    break
                
                time.sleep(self.config['sleep_after_list'])
                
            except HttpError as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞: {e}")
                break
        
        return all_ids

    # ==================== –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø ====================
    
    def group_by_similar_subjects(self, messages: List[Tuple[datetime, str, str]]) -> List[Tuple[datetime, str, str]]:
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–∏—Å–µ–º –ø–æ –ø–æ—Ö–æ–∂–∏–º —Ç–µ–º–∞–º."""
        if not FUZZYWUZZY_AVAILABLE:
            self.logger.warning("‚ö†Ô∏è fuzzywuzzy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–ø—É—Å–∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏.")
            return messages
        
        threshold = self.config['subject_similarity_threshold']
        processed = [(self.clean_subject(subj), dt, mid, subj) for dt, mid, subj in messages]
        
        clusters = []
        unclustered = list(processed)
        
        while unclustered:
            ref_clean, ref_dt, ref_mid, ref_subj = unclustered.pop(0)
            current_cluster = [(ref_dt, ref_mid, ref_subj)]
            
            to_remove = []
            for item in unclustered:
                test_clean, test_dt, test_mid, test_subj = item
                if fuzz.ratio(ref_clean, test_clean) >= threshold:
                    current_cluster.append((test_dt, test_mid, test_subj))
                    to_remove.append(item)
            
            for item in to_remove:
                unclustered.remove(item)
            
            clusters.append(current_cluster)
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ —Ä–∞–∑–º–µ—Ä—É
        clusters.sort(key=len, reverse=True)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫
        reordered = []
        for cluster in clusters:
            cluster.sort(key=lambda x: x[0])
            reordered.extend(cluster)
        
        return reordered

    # ==================== BACKUP ====================
    
    def export_emails_before_delete(self, messages_info: List[Tuple[datetime, str, str]]) -> Optional[str]:
        """–≠–∫—Å–ø–æ—Ä—Ç –ø–∏—Å–µ–º –≤ JSON –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º."""
        if not messages_info or not self.config['auto_backup']:
            return None
        
        os.makedirs(self.config['backup_dir'], exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_file = os.path.join(self.config['backup_dir'], f'backup_{timestamp}.json')
        
        self.logger.info(f"üíæ –°–æ–∑–¥–∞–Ω–∏–µ backup: {backup_file}")
        
        backup_data = []
        progress_bar = tqdm(
            messages_info, 
            desc="Backup", 
            unit="–ø–∏—Å–µ–º"
        ) if TQDM_AVAILABLE else messages_info
        
        for dt, msg_id, subj in progress_bar:
            try:
                msg = self.service.users().messages().get(
                    userId='me', 
                    id=msg_id, 
                    format='full'
                ).execute()
                backup_data.append({
                    'id': msg_id,
                    'date': dt.isoformat(),
                    'subject': subj,
                    'full_data': msg
                })
                self.stats['backed_up'] += 1
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ backup –¥–ª—è {msg_id}: {e}")
        
        if TQDM_AVAILABLE:
            progress_bar.close()
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(backup_data, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"‚úÖ Backup —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {backup_file} ({len(backup_data)} –ø–∏—Å–µ–º)")
        return backup_file

    # ==================== –£–î–ê–õ–ï–ù–ò–ï ====================
    
    def trash_emails_batch(self, messages_info: List[Tuple[datetime, str, str]]):
        """–ú–∞—Å—Å–æ–≤–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –ø–∏—Å–µ–º –±–∞—Ç—á–∞–º–∏ (–±—ã—Å—Ç—Ä–µ–µ –≤ 10 —Ä–∞–∑!)."""
        if not messages_info:
            return
        
        total = len(messages_info)
        batch_size = self.config['batch_delete_size']
        
        self.logger.info(f"üóëÔ∏è –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ {total} –ø–∏—Å–µ–º –≤ –∫–æ—Ä–∑–∏–Ω—É (batch —Ä–µ–∂–∏–º)...")
        
        def batch_callback(request_id, response, exception):
            if exception:
                self.stats['errors'] += 1
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞: {exception}")
            else:
                # –í –±–∞—Ç—á–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –±—ã —Å–∫–∞–∑–∞–ª, —Å–∫–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ. 
                # –°—á–∏—Ç–∞–µ–º, —á—Ç–æ –≤—Å–µ –ø–∏—Å—å–º–∞ –≤ –∑–∞–ø—Ä–æ—Å–µ —É—Å–ø–µ—à–Ω—ã, –µ—Å–ª–∏ –Ω–µ—Ç –æ–±—â–µ–π –æ—à–∏–±–∫–∏
                pass
        
        trashed_count_in_batch = 0
        
        progress_bar = tqdm(
            total=total, 
            desc="–ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≤ –ö–æ—Ä–∑–∏–Ω—É (Batch)", 
            unit="–ø–∏—Å–µ–º"
        ) if TQDM_AVAILABLE else None

        for i in range(0, total, batch_size):
            chunk = messages_info[i:i + batch_size]
            batch = self.service.new_batch_http_request(callback=batch_callback)
            
            for dt, msg_id, subj in chunk:
                batch.add(
                    self.service.users().messages().trash(userId='me', id=msg_id)
                )
                
            try:
                batch.execute()
                trashed_count_in_batch += len(chunk)
                if progress_bar:
                    progress_bar.update(len(chunk))
                time.sleep(self.config['delay_between_requests'])
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ batch –æ–ø–µ—Ä–∞—Ü–∏–∏: {e}")
                
        if progress_bar:
            progress_bar.close()

        self.stats['trashed'] += trashed_count_in_batch
        self.logger.info(f"‚úÖ Batch –∑–∞–≤–µ—Ä—à–µ–Ω. –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ: {trashed_count_in_batch}")


    def trash_emails_interactive(self, messages_info: List[Tuple[datetime, str, str]]):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Å –ø—Ä–µ–≤—å—é –∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º."""
        if not messages_info:
            return
        
        PREVIEW_SIZE = 20
        total = len(messages_info)
        
        print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {total} –ø–∏—Å–µ–º. –ü–æ–∫–∞–∑—ã–≤–∞—é –ø–µ—Ä–≤—ã–µ {min(total, PREVIEW_SIZE)}:\n")
        print("-" * 80)
        
        for i, (dt, msg_id, subj) in enumerate(messages_info[:PREVIEW_SIZE]):
            date_str = dt.astimezone().strftime('%Y-%m-%d %H:%M:%S')
            subj_short = subj[:55] + '...' if len(subj) > 55 else subj
            print(f"[{i+1:02}] {date_str} | {subj_short}")
        
        print("-" * 80)
        
        if self.config['dry_run']:
            print("‚ö†Ô∏è –†–ï–ñ–ò–ú DRY-RUN: –ø–∏—Å—å–º–∞ –ù–ï –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã.")
            self.stats['skipped'] = total
            return
        
        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        action = input(f"\n–£–¥–∞–ª–∏—Ç—å {total} –ø–∏—Å–µ–º? (y/n/c[ustom]/b[ackup]): ").strip().lower()
        
        messages_to_delete = []
        skipped_count = 0
        
        if action == 'y':
            messages_to_delete = messages_info
        
        elif action == 'c':
            keep_str = input(f"–°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø–∏—Å–µ–º –æ—Å—Ç–∞–≤–∏—Ç—å? (0-{total}): ").strip()
            try:
                keep_count = int(keep_str)
                keep_count = max(0, min(keep_count, total))
            except ValueError:
                keep_count = 0
            
            messages_to_delete = messages_info[:-keep_count] if keep_count > 0 else messages_info
            skipped_count = keep_count
            
            if not messages_to_delete:
                print("‚úÖ –í—Å–µ –ø–∏—Å—å–º–∞ –æ—Å—Ç–∞–≤–ª–µ–Ω—ã.")
                self.stats['skipped'] = total
                return
            
            print(f"üìù –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ: {len(messages_to_delete)}, –æ—Å—Ç–∞–≤–ª–µ–Ω–æ: {skipped_count}")
        
        elif action == 'b':
            # –°–æ–∑–¥–∞—Ç—å backup –∏ —É–¥–∞–ª–∏—Ç—å
            self.export_emails_before_delete(messages_info)
            messages_to_delete = messages_info
        
        else:
            print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞.")
            self.stats['skipped'] = total
            return
        
        # –£–¥–∞–ª–µ–Ω–∏–µ
        if self.config['use_batch_delete'] and len(messages_to_delete) >= 10:
            self.trash_emails_batch(messages_to_delete)
        else:
            # –ï—Å–ª–∏ –º–∞–ª–æ –ø–∏—Å–µ–º, —É–¥–∞–ª—è–µ–º –ø–æ –æ–¥–Ω–æ–º—É, —á—Ç–æ–±—ã –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –±—ã–ª —Ç–æ—á–Ω–µ–µ
            initial_trashed = self.stats['trashed']
            progress_bar = tqdm(
                messages_to_delete, 
                desc="–£–¥–∞–ª–µ–Ω–∏–µ", 
                unit="–ø–∏—Å–µ–º"
            ) if TQDM_AVAILABLE else messages_to_delete
            
            for dt, msg_id, subj in progress_bar:
                self.trash_single_message_with_retry(msg_id)
                time.sleep(self.config['delay_between_requests'])
            
            if TQDM_AVAILABLE:
                progress_bar.close()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É trashed –≤ —ç—Ç–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –≤—ã–∑–æ–≤–µ
            trashed_in_call = self.stats['trashed'] - initial_trashed
            self.stats['trashed'] = initial_trashed + trashed_in_call
            
            
        self.stats['skipped'] += skipped_count
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –£–¥–∞–ª–µ–Ω–æ: {len(messages_to_delete)}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}")

    def trash_single_message_with_retry(self, msg_id: str) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –ø–∏—Å—å–º–∞ —Å retry."""
        retry_count = 0
        
        while retry_count < self.config['max_retries']:
            try:
                self.service.users().messages().trash(userId='me', id=msg_id).execute()
                self.stats['trashed'] += 1
                return True
            except HttpError as e:
                retry_count += 1
                if e.resp.status in [429, 403]:
                    backoff_time = self.exponential_backoff(retry_count)
                    time.sleep(backoff_time)
                else:
                    self.stats['errors'] += 1
                    return False
            except Exception:
                self.stats['errors'] += 1
                return False
        
        return False

    # ==================== –û–¢–ü–ò–°–ö–ê –û–¢ –†–ê–°–°–´–õ–û–ö ====================
    
    def find_unsubscribe_link(self, msg_id: str) -> Optional[str]:
        """–ü–æ–∏—Å–∫ —Å—Å—ã–ª–∫–∏ –¥–ª—è –æ—Ç–ø–∏—Å–∫–∏ –≤ –ø–∏—Å—å–º–µ."""
        try:
            msg = self.service.users().messages().get(
                userId='me', 
                id=msg_id, 
                format='full'
            ).execute()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ List-Unsubscribe
            headers = msg.get('payload', {}).get('headers', [])
            for h in headers:
                if h.get('name', '').lower() == 'list-unsubscribe':
                    link = h['value']
                    # –ò—â–µ–º HTTP/HTTPS —Å—Å—ã–ª–∫—É –≤ —É–≥–ª–æ–≤—ã—Ö —Å–∫–æ–±–∫–∞—Ö
                    match = re.search(r'<(https?://[^>]+)>', link)
                    if match:
                        return match.group(1)
            
            # –ò—â–µ–º –≤ —Ç–µ–ª–µ –ø–∏—Å—å–º–∞
            body = self._get_email_body(msg)
            patterns = [
                r'(https?://[^\s]+unsubscribe[^\s"<>]*)',
                r'(https?://[^\s]+opt-out[^\s"<>]*)',
                r'(https?://[^\s]+remove[^\s"<>]*)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, body, re.IGNORECASE)
                if match:
                    url = match.group(1).rstrip('.,;)')
                    return url
        
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–∫–∏ –æ—Ç–ø–∏—Å–∫–∏: {e}")
            
        return None

    def _get_email_body(self, msg: dict) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ç–µ–ª–∞ –ø–∏—Å—å–º–∞."""
        
        def decode_part(part):
            body_data = part.get('body', {}).get('data', '')
            if body_data:
                return base64.urlsafe_b64decode(body_data).decode('utf-8', errors='ignore')
            return ''
        
        payload = msg.get('payload', {})
        
        # –ü—Ä–æ—Å—Ç–æ–µ –ø–∏—Å—å–º–æ
        if 'body' in payload and payload['body'].get('data'):
            return decode_part(payload)
        
        # Multipart
        if 'parts' in payload:
            text = ''
            for part in payload['parts']:
                if part.get('mimeType') == 'text/plain':
                    text += decode_part(part)
                elif part.get('mimeType') == 'text/html':
                    text += decode_part(part)
            return text
        
        return ''

    def interactive_unsubscribe(self, sender_email: str):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –æ—Ç–ø–∏—Å–∫–∞ –æ—Ç —Ä–∞—Å—Å—ã–ª–∫–∏."""
        print(f"\nüìß –ü–æ–∏—Å–∫ –ø–∏—Å–µ–º –æ—Ç {sender_email}...")
        
        query = f"from:{sender_email}"
        messages = self.find_emails_by_criteria(query)
        
        if not messages:
            print(f"‚ùå –ü–∏—Å—å–º–∞ –æ—Ç {sender_email} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø–∏—Å—å–º–æ
        latest = messages[-1]
        dt, msg_id, subject = latest
        
        print(f"\nüì¨ –ü–æ—Å–ª–µ–¥–Ω–µ–µ –ø–∏—Å—å–º–æ:")
        print(f"    –¢–µ–º–∞: {subject}")
        print(f"    –î–∞—Ç–∞: {dt.astimezone().strftime('%Y-%m-%d %H:%M:%S')}")
        
        print("\nüîç –ü–æ–∏—Å–∫ —Å—Å—ã–ª–∫–∏ –¥–ª—è –æ—Ç–ø–∏—Å–∫–∏...")
        unsubscribe_link = self.find_unsubscribe_link(msg_id)
        
        if not unsubscribe_link:
            print("‚ö†Ô∏è –°—Å—ã–ª–∫–∞ –¥–ª—è –æ—Ç–ø–∏—Å–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            print("     –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–ø–∏—Å–∞—Ç—å—Å—è –≤—Ä—É—á–Ω—É—é –∏–∑ –ø–∏—Å—å–º–∞.")
            return
        
        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞:")
        print(f"    {unsubscribe_link}\n")
        
        # –í–∞—Ä–∏–∞–Ω—Ç—ã –¥–µ–π—Å—Ç–≤–∏–π
        print("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
        print("  1 - –û—Ç–∫—Ä—ã—Ç—å –≤ –±—Ä–∞—É–∑–µ—Ä–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
        print("  2 - –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Å—Å—ã–ª–∫—É")
        if REQUESTS_AVAILABLE:
            print("  3 - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ—Ö–æ–¥ (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ!)")
        print("  0 - –û—Ç–º–µ–Ω–∞")
        
        choice = input("\n–í—ã–±–æ—Ä: ").strip()
        
        if choice == '1':
            print("üåê –û—Ç–∫—Ä—ã–≤–∞—é –±—Ä–∞—É–∑–µ—Ä...")
            webbrowser.open(unsubscribe_link)
            print("‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç–µ –æ—Ç–ø–∏—Å–∫—É –≤ –±—Ä–∞—É–∑–µ—Ä–µ.")
        
        elif choice == '2':
            if PYPERCLIP_AVAILABLE:
                try:
                    pyperclip.copy(unsubscribe_link)
                    print("‚úÖ –°—Å—ã–ª–∫–∞ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞!")
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
                    print(f"    –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤—Ä—É—á–Ω—É—é: {unsubscribe_link}")
            else:
                print("‚ö†Ô∏è pyperclip –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
                print(f"    –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤—Ä—É—á–Ω—É—é: {unsubscribe_link}")
        
        elif choice == '3' and REQUESTS_AVAILABLE:
            confirm = input("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï! –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ—Ö–æ–¥ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–±–µ–∑–æ–ø–∞—Å–µ–Ω.\n"
                              "    –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (yes/no): ").strip().lower()
            
            if confirm == 'yes':
                try:
                    response = requests.get(unsubscribe_link, timeout=10)
                    if response.status_code == 200:
                        print("‚úÖ –ó–∞–ø—Ä–æ—Å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ—á—Ç—É.")
                    else:
                        print(f"‚ö†Ô∏è –°—Ç–∞—Ç—É—Å: {response.status_code}. –í–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ.")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            else:
                print("–û—Ç–º–µ–Ω–µ–Ω–æ.")
        
        else:
            print("‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ.")

    # ==================== –°–¢–ê–¢–ò–°–¢–ò–ö–ê ====================
    
    def load_sender_counts(self, filename: str = 'sender_counts.csv') -> Optional['pd.DataFrame']:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π –∏–∑ CSV."""
        if not PANDAS_AVAILABLE:
            return None
        
        if not os.path.exists(filename):
            return None
        
        try:
            df = pd.read_csv(filename)
            
            if 'sender_email' not in df.columns or 'message_count' not in df.columns:
                self.logger.error("‚ùå CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'sender_email' –∏ 'message_count'")
                return None
            
            df['message_count'] = pd.to_numeric(df['message_count'], errors='coerce').fillna(0).astype(int)
            df = df.sort_values('message_count', ascending=False).reset_index(drop=True)
            
            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {len(df)} –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π")
            return df
        
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")
            return None

    def save_stats(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã."""
        os.makedirs(self.config['stats_dir'], exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        stats_file = os.path.join(self.config['stats_dir'], f'stats_{timestamp}.json')
        
        detailed_stats = {
            'timestamp': datetime.now().isoformat(),
            'summary': self.stats,
            'config': self.config,
            'dry_run': self.config['dry_run']
        }
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_stats, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {stats_file}")

    def display_stats(self):
        """–í—ã–≤–æ–¥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."""
        print("\n" + "="*50)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–ë–û–¢–´")
        print("="*50)
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ –ø–∏—Å–µ–º:     {self.stats['found']}")
        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ:            {self.stats['trashed']}")
        print(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ:          {self.stats['skipped']}")
        print(f"üíæ Backup —Å–æ–∑–¥–∞–Ω:      {self.stats['backed_up']}")
        print(f"‚ùå –û—à–∏–±–æ–∫:             {self.stats['errors']}")
        print("="*50)


# ==================== CLI ====================

def parse_arguments():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(
        description='Gmail Cleaner Pro - –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ—á—Ç–æ–π'
    )
    parser.add_argument('--sender', type=str, help='Email –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è')
    parser.add_argument('--days', type=int, help='–ü–∏—Å—å–º–∞ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π')
    parser.add_argument('--dry-run', action='store_true', help='–†–µ–∂–∏–º –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è')
    parser.add_argument('--batch-size', type=int, default=100, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞')
    parser.add_argument('--no-backup', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å auto-backup')
    parser.add_argument('--unsubscribe', type=str, help='–û—Ç–ø–∏—Å–∞—Ç—å—Å—è –æ—Ç —Ä–∞—Å—Å—ã–ª–∫–∏ (email)')
    
    return parser.parse_args()


# ==================== MAIN ====================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã."""
    
    args = parse_arguments()
    
    config_override = {
        'dry_run': args.dry_run,
        'batch_size': args.batch_size,
        'auto_backup': not args.no_backup,
        'use_batch_delete': True
    }
    
    cleaner = GmailCleanerPro(config=config_override)
    
    print("="*60)
    print("      üìß GMAIL CLEANER PRO v2.1 - –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—á–∏–π —Å–∫—Ä–∏–ø—Ç üöÄ")
    print("="*60)
    
    try:
        cleaner.authenticate_gmail_api()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        return
    
    # --- –ë–õ–û–ö –û–ë–†–ê–ë–û–¢–ö–ò CLI –ê–†–ì–£–ú–ï–ù–¢–û–í ---
    if args.unsubscribe:
        cleaner.interactive_unsubscribe(args.unsubscribe)
        return
    
    if args.sender:
        print("üí° –ó–∞–ø—É—â–µ–Ω –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º –æ—á–∏—Å—Ç–∫–∏ —á–µ—Ä–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç—ã CLI.")
        query = cleaner.build_search_query(
            sender_email=args.sender,
            days_ago=args.days,
            additional_query=None,
            min_size_mb=None
        )
        if query:
            messages_info = cleaner.find_emails_by_criteria(query)
            if messages_info:
                messages_info = cleaner.group_by_similar_subjects(messages_info)
                cleaner.trash_emails_interactive(messages_info)
        cleaner.display_stats()
        cleaner.save_stats()
        return

    # --- –ë–õ–û–ö –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–û–ì–û –¶–ò–ö–õ–ê (–ö–∞–∫ –≤—ã –ø—Ä–æ—Å–∏–ª–∏) ---
    
    sender_df = cleaner.load_sender_counts() if PANDAS_AVAILABLE else None
    
    if sender_df is not None:
        display_top_senders(sender_df)
    
    while True:
        print("\n" + "="*70)
        print("          ‚ú® –ì–û–¢–û–í–ù–û–°–¢–¨ –ö –ß–ò–°–¢–ö–ï (–í–≤–µ–¥–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
        print("="*70)
        
        sender_input = input("Email/–¥–æ–º–µ–Ω –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –¥–ª—è —á–∏—Å—Ç–∫–∏ (–∏–ª–∏ 'q', 'top', 'unsub'): ").strip()
        
        if sender_input.lower() in ['q', 'exit', 'quit']:
            print("üëã –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã.")
            break
            
        if sender_input.lower() == 'top':
            if sender_df is not None:
                display_top_senders(sender_df)
            else:
                print("‚ö†Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Pandas –∏ —Å–æ–∑–¥–∞–π—Ç–µ sender_counts.csv.")
            continue
            
        if sender_input.lower() == 'unsub':
            unsub_email = input("–í–≤–µ–¥–∏—Ç–µ email –¥–ª—è –æ—Ç–ø–∏—Å–∫–∏ (e.g., mail@newsletter.com): ").strip()
            if unsub_email:
                cleaner.interactive_unsubscribe(unsub_email)
            continue
            
        if not sender_input:
            print("‚ö†Ô∏è –ù–µ —É–∫–∞–∑–∞–Ω –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
            continue
            
        days = input("–ü–∏—Å—å–º–∞ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π (–ø—É—Å—Ç–æ ‚Äî –≤—Å–µ): ").strip()
        days_ago = int(days) if days.isdigit() else None
        
        size = input("–ü–∏—Å—å–º–∞ –∫—Ä—É–ø–Ω–µ–µ N –ú–ë (–ø—É—Å—Ç–æ ‚Äî –≤—Å–µ): ").strip()
        min_size_mb = float(size) if size.replace('.', '', 1).isdigit() else None
        
        additional_query = input("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'subject:ads' –∏–ª–∏ –ø—É—Å—Ç–æ): ").strip()

        query = cleaner.build_search_query(
            sender_email=sender_input, 
            days_ago=days_ago, 
            additional_query=additional_query,
            min_size_mb=min_size_mb
        )
        
        if query is None:
            continue
            
        messages_info = cleaner.find_emails_by_criteria(query)

        if messages_info:
            messages_info = cleaner.group_by_similar_subjects(messages_info)
            cleaner.trash_emails_interactive(messages_info)
        else:
            print("üì≠ –ü–∏—Å—å–º–∞ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

    # –í—ã–≤–æ–¥ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ—Å–ª–µ –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞
    cleaner.display_stats()
    cleaner.save_stats()
    
if __name__ == '__main__':
    main()